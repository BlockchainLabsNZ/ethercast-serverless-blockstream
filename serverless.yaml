service:
  name: serverless-blockstream

plugins:
  - serverless-pseudo-parameters
  - serverless-dynamodb-autoscaling
  - serverless-webpack

custom:
  webpackIncludeModules: true # enable auto-packing of external modules
  region: ${opt:region, self:provider.region}
  stage: ${opt:stage, self:provider.stage}
  prefix: ${self:service}-${self:custom.stage}
  drainBlockQueueLambdaName: ${self:custom.prefix}-drain-block-queue
  newBlockQueueName: ${self:custom.prefix}-new-blocks.fifo
  logFirehoseQueue: ${self:custom.prefix}-log-firehose.fifo
  baseDynamoDDBCapacity: 2
  alertNotificationEmail: "aws-alerts+${self:custom.prefix}@ethercast.io" # where cloudwatch alarms alert to
  capacities:
    - table: BlocksTable  # DynamoDB Resource
      index:              # List or single index name
        - ByBlockNumber
      read:
        minimum: ${self:custom.baseDynamoDDBCapacity}        # Minimum read capacity
        maximum: 1000      # Maximum read capacity
        usage: 0.8        # Targeted usage percentage
      write:
        minimum: ${self:custom.baseDynamoDDBCapacity}        # Minimum write capacity
        maximum: 1000      # Maximum write capacity
        usage: 0.8        # Targeted usage percentage

provider:
  name: aws
  runtime: nodejs6.10
  environment: # service wide environment variables
    BLOCKSTREAM_STATE_TABLE: ${self:custom.prefix}-bs-state # the table containing the state of blockstream
    BLOCKS_TABLE: ${self:custom.prefix}-blocks # the table containing full blocks and their logs (compressed)
    DRAIN_BLOCK_QUEUE_LAMBDA_NAME: ${self:custom.drainBlockQueueLambdaName} # The lambda triggered when blocks are added to the queue
    NEW_BLOCK_QUEUE_NAME: ${self:custom.newBlockQueueName}  # Queue that receives new blocks
    LOG_FIREHOSE_QUEUE_NAME: ${self:custom.logFirehoseQueue} # Queue that receives log events
    SRC_NODE_URL: "https://mainnet.infura.io/0eep3H3CSiqitPXv0aOy" # the ethereum node URL that is used
    NUM_BLOCKS_DELAY: "0" # how many blocks behind the chain we wait to send logs
    BLOCK_DATA_TTL_MS: "604800000" # 7 days in milliseconds
    LOG_LEVEL: "info" # info log level
    NETWORK_ID: "1" # id of the network, validated against the node

  iamRoleStatements: # permissions for all of your functions can be set here
    - Effect: Allow
      Action: # Gives permission to DynamoDB tables in a specific region
        - dynamodb:Query
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:BatchWriteItem
        - dynamodb:BatchGetItem
      Resource:
        - "arn:aws:dynamodb:${self:custom.region}:#{AWS::AccountId}:table/${self:provider.environment.BLOCKSTREAM_STATE_TABLE}"
        - "arn:aws:dynamodb:${self:custom.region}:#{AWS::AccountId}:table/${self:provider.environment.BLOCKS_TABLE}"
        - "arn:aws:dynamodb:${self:custom.region}:#{AWS::AccountId}:table/${self:provider.environment.BLOCKS_TABLE}/*"
    - Effect: Allow
      Action: # Gives permission to push logs to the SQS queue
        - sqs:SendMessage
        - sqs:SendMessageBatch
        - sqs:ReceiveMessage
        - sqs:DeleteMessage
        - sqs:GetQueueUrl
      Resource:
        - "arn:aws:sqs:${self:custom.region}:#{AWS::AccountId}:${self:custom.newBlockQueueName}"
    - Effect: Allow
      Action: # Gives the poller permission to execute the drain q lambda
        - lambda:InvokeFunction
      Resource:
        - "arn:aws:lambda:${self:custom.region}:#{AWS::AccountId}:function:${self:custom.drainBlockQueueLambdaName}"
    - Effect: Allow
      Action: # Gives permission to push logs to the SQS queue
        - sqs:SendMessage
        - sqs:SendMessageBatch
        - sqs:GetQueueUrl
      Resource:
        - "arn:aws:sqs:${self:custom.region}:#{AWS::AccountId}:${self:custom.logFirehoseQueue}"

functions:
  poll-for-blocks:
    handler: src/poll.start
    memorySize: 256 # optional, in MB, default is 1024
    timeout: 120
    events:
      - schedule:
          rate: rate(2 minutes)
          enabled: true

  drain-queue:
    name: ${self:custom.drainBlockQueueLambdaName}
    handler: src/drain.start
    memorySize: 256
    timeout: 120

resources:
  Outputs:
    LogFirehoseQueueName:
      Description: The name of the log firehose SQS queue to which all incoming logs events are sent
      Value:
        Fn::GetAtt:
          - "LogFirehoseQueue"
          - "QueueName"
      Export:
        Name: ${self:custom.stage}-LogFirehoseQueueName
  Resources:
    BlockStreamStateTable: # This table is throttled and should not autoscale
        Type: AWS::DynamoDB::Table
        Properties:
          TableName: ${self:provider.environment.BLOCKSTREAM_STATE_TABLE}
          AttributeDefinitions:
            - AttributeName: network_id
              AttributeType: N
          KeySchema:
            - AttributeName: network_id
              KeyType: HASH
          ProvisionedThroughput:
            ReadCapacityUnits: ${self:custom.baseDynamoDDBCapacity}
            WriteCapacityUnits: ${self:custom.baseDynamoDDBCapacity}

    BlocksTable: # This table's autoscaling is to handle downtimes or node switching. When it needs to catch up, it costs more.
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:provider.environment.BLOCKS_TABLE}
        AttributeDefinitions:
          - AttributeName: hash
            AttributeType: S
          - AttributeName: number
            AttributeType: S
        KeySchema:
          - AttributeName: hash
            KeyType: HASH
          - AttributeName: number
            KeyType: RANGE
        ProvisionedThroughput:
          ReadCapacityUnits: ${self:custom.baseDynamoDDBCapacity}
          WriteCapacityUnits: ${self:custom.baseDynamoDDBCapacity}
        TimeToLiveSpecification:
          AttributeName: ttl
          Enabled: true
        GlobalSecondaryIndexes:
          -
            IndexName: ByBlockNumber
            KeySchema:
              - AttributeName: number
                KeyType: HASH
            Projection:
              ProjectionType: KEYS_ONLY
            ProvisionedThroughput:
              ReadCapacityUnits: ${self:custom.baseDynamoDDBCapacity}
              WriteCapacityUnits: ${self:custom.baseDynamoDDBCapacity}

    NewBlockQueue:
      Type: AWS::SQS::Queue
      Properties:
        QueueName: ${self:custom.newBlockQueueName}
        FifoQueue: true
        MessageRetentionPeriod: 1209600
        VisibilityTimeout: 60

    LogFirehoseQueue:
      Type: AWS::SQS::Queue
      Properties:
        QueueName: ${self:custom.logFirehoseQueue}
        FifoQueue: true
        MessageRetentionPeriod: 1209600
        VisibilityTimeout: 60

    AlarmTopic:
      Type: AWS::SNS::Topic
      Properties:
        Subscription:
          - Endpoint: ${self:custom.alertNotificationEmail}
            Protocol: email

    NewBlockQueueDepthAlarm:
      Type: AWS::CloudWatch::Alarm
      Properties:
        AlarmDescription: "Alarm if new blocks are not being removed from the queue"
        Namespace: "AWS/SQS"
        MetricName: ApproximateNumberOfMessagesVisible
        Dimensions:
          - Name: QueueName
            Value: ${self:custom.newBlockQueueName}
        Statistic: Maximum
        Period: 60
        Threshold: 5
        EvaluationPeriods: 3
        ComparisonOperator: GreaterThanThreshold
        AlarmActions:
          - Ref: AlarmTopic
        OKActions:
          - Ref: AlarmTopic
        TreatMissingData: breaching

    NewBlockQueueActiveAlarm:
      Type: AWS::CloudWatch::Alarm
      Properties:
        AlarmDescription: "Alarm if new blocks have not been entered into queue in five minutes"
        Namespace: "AWS/SQS"
        MetricName: NumberOfMessagesSent
        Dimensions:
          - Name: QueueName
            Value: ${self:custom.newBlockQueueName}
        Statistic: Sum
        Period: 300
        Threshold: 0
        EvaluationPeriods: 3
        ComparisonOperator: LessThanOrEqualToThreshold
        AlarmActions:
          - Ref: AlarmTopic
        OKActions:
          - Ref: AlarmTopic
        TreatMissingData: breaching

    LogFirehoseQueueDepthAlarm:
      Type: AWS::CloudWatch::Alarm
      Properties:
        AlarmDescription: "Alarm if new logs are not being removed from the queue"
        Namespace: "AWS/SQS"
        MetricName: ApproximateNumberOfMessagesVisible
        Dimensions:
          - Name: QueueName
            Value: ${self:custom.logFirehoseQueue}
        Statistic: Maximum
        Period: 60
        Threshold: 500
        EvaluationPeriods: 3
        ComparisonOperator: GreaterThanThreshold
        AlarmActions:
          - Ref: AlarmTopic
        OKActions:
          - Ref: AlarmTopic
        TreatMissingData: breaching

    LogFirehoseQueueActiveAlarm:
      Type: AWS::CloudWatch::Alarm
      Properties:
        AlarmDescription: "Alarm if logs have not been added to queue in five minutes"
        Namespace: "AWS/SQS"
        MetricName: NumberOfMessagesSent
        Dimensions:
          - Name: QueueName
            Value: ${self:custom.logFirehoseQueue}
        Statistic: Sum
        Period: 300
        Threshold: 0
        EvaluationPeriods: 3
        ComparisonOperator: LessThanOrEqualToThreshold
        AlarmActions:
          - Ref: AlarmTopic
        OKActions:
          - Ref: AlarmTopic
        TreatMissingData: breaching
